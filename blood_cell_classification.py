# -*- coding: utf-8 -*-
"""Blood cell classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n9fFH5mj_QdQ_u9uK4uU6eYgpXy-Hskd
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import os
import os.path
from pathlib import Path
import glob

Train_Data_Path = Path("/content/drive/MyDrive/dataset2-master/dataset2-master/images/TRAIN")

Test_Data_Path = Path("/content/drive/MyDrive/dataset2-master/dataset2-master/images/TEST")

Validation_Data_Path = Path("/content/drive/MyDrive/dataset2-master/dataset2-master/images/TEST_SIMPLE")

Train_JPG_Path = list(Train_Data_Path.glob(r"**/*.jpeg"))

Test_JPG_Path = list(Test_Data_Path.glob(r"**/*.jpeg"))

Validation_JPG_Path = list(Validation_Data_Path.glob(r"**/*.jpeg"))

print(Train_JPG_Path)

# filtering label from path
Train_JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Train_JPG_Path))

print("EOSINOPHIL: ", Train_JPG_Labels.count("EOSINOPHIL"))
print("LYMPHOCYTE: ", Train_JPG_Labels.count("LYMPHOCYTE"))
print("MONOCYTE: ", Train_JPG_Labels.count("MONOCYTE"))
print("NEUTROPHIL: ", Train_JPG_Labels.count("NEUTROPHIL"))

Test_JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Test_JPG_Path))

print("EOSINOPHIL: ", Test_JPG_Labels.count("EOSINOPHIL"))
print("LYMPHOCYTE: ", Test_JPG_Labels.count("LYMPHOCYTE"))
print("MONOCYTE: ", Test_JPG_Labels.count("MONOCYTE"))
print("NEUTROPHIL: ", Test_JPG_Labels.count("NEUTROPHIL"))

Validation_JPG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Validation_JPG_Path))
print("EOSINOPHIL: ", Validation_JPG_Labels.count("EOSINOPHIL"))
print("LYMPHOCYTE: ", Validation_JPG_Labels.count("LYMPHOCYTE"))
print("MONOCYTE: ", Validation_JPG_Labels.count("MONOCYTE"))
print("NEUTROPHIL: ", Validation_JPG_Labels.count("NEUTROPHIL"))

#Train

Train_JPG_Path_Series = pd.Series(Train_JPG_Path,name="JPG").astype(str)
Train_JPG_Labels_Series = pd.Series(Train_JPG_Labels,name="CATEGORY")
Main_Train_Data = pd.concat([Train_JPG_Path_Series,Train_JPG_Labels_Series],axis=1)

#TEST
Test_JPG_Path_Series = pd.Series(Test_JPG_Path,name="JPG").astype(str)
Test_JPG_Labels_Series = pd.Series(Test_JPG_Labels,name="CATEGORY")
Main_Test_Data = pd.concat([Test_JPG_Path_Series,Test_JPG_Labels_Series],axis=1)

#VALIDATION
Validation_JPG_Path_Series = pd.Series(Validation_JPG_Path,name="JPG").astype(str)
Validation_JPG_Labels_Series = pd.Series(Validation_JPG_Labels,name="CATEGORY")
Main_Validation_Data = pd.concat([Validation_JPG_Path_Series,Validation_JPG_Labels_Series],axis=1)

#shuffling the data. so training converge fast and it prevents any bias.

Main_Train_Data = Main_Train_Data.sample(frac=1).reset_index(drop=True)
Main_Train_Data.head()

Main_Test_Data = Main_Test_Data.sample(frac=1).reset_index(drop=True)
Main_Test_Data

Main_Validation_Data = Main_Validation_Data.sample(frac=1).reset_index(drop=True)
Main_Validation_Data.head()

"""## Data visualization"""

sns.countplot(Main_Train_Data["CATEGORY"])
plt.show()

sns.countplot(Main_Test_Data["CATEGORY"])
plt.show()

sns.countplot(Main_Validation_Data["CATEGORY"])
plt.show()

x = plt.imread(Main_Train_Data["JPG"][100])
plt.imshow(x)
plt.xlabel(x.shape)
plt.title(Main_Train_Data["CATEGORY"][100])

from PIL import Image
from keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from keras.utils.np_utils import to_categorical
from sklearn.model_selection import train_test_split
from keras import regularizers

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve

from keras.optimizers import RMSprop,Adam,Optimizer,Optimizer

from tensorflow.keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\
                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D
from keras import models
from keras import layers
import tensorflow as tf
from keras.applications import VGG16,VGG19,inception_v3
from keras import backend as K

Train_Generator = ImageDataGenerator(rescale=1./255,
                                    zoom_range=0.3,
                                    shear_range=0.3,
                                    rotation_range=40,
                                    horizontal_flip=True,
                                    fill_mode="nearest")

Test_Validation_Generator = ImageDataGenerator(rescale=1./255,validation_split=0.5)

Train_IMG_Set = Train_Generator.flow_from_dataframe(dataframe=Main_Train_Data,
                                                   x_col="JPG",
                                                   y_col="CATEGORY",
                                                   color_mode="rgb",
                                                   class_mode="categorical",
                                                   subset="training",
                                                   seed=42,
                                                   batch_size=32,
                                                   target_size=(220,220))

Test_IMG_Set = Test_Validation_Generator.flow_from_dataframe(dataframe=Main_Test_Data,
                                                            x_col="JPG",
                                                            y_col="CATEGORY",
                                                            color_mode="rgb",
                                                            class_mode="categorical",
                                                            seed=42,
                                                            batch_size=32,
                                                            target_size=(220,220))

Validation_IMG_Set = Test_Validation_Generator.flow_from_dataframe(dataframe=Main_Validation_Data,
                                                                  x_col="JPG",
                                                                  y_col="CATEGORY",
                                                                  color_mode="rgb",
                                                                  class_mode="categorical",
                                                                  seed=42,
                                                                  batch_Size=32,
                                                                  target_size=(220,200),
                                                                  subset="validation")

"""##CNN"""

Model = Sequential()

Model.add(SeparableConv2D(32,3,activation="relu",input_shape=(220,220,3)))

Model.add(BatchNormalization())
Model.add(MaxPooling2D((2)))

#
# Model.add(SeparableConv2D(64,3,activation="relu"))
# Model.add(SeparableConv2D(128,(3,3), activation="relu"))
# Model.add(Dropout(0.5))
# Model.add(MaxPooling2D((2)))

#
Model.add(SeparableConv2D(32,3,activation="relu"))
Model.add(SeparableConv2D(32,3,activation="relu"))
Model.add(Dropout(0.5))
Model.add(GlobalAveragePooling2D())

#
Model.add(Flatten())
Model.add(Dense(16,activation="relu"))
Model.add(Dropout(0.5))
Model.add(Dense(4,activation="softmax"))

Call_Back = tf.keras.callbacks.EarlyStopping(monitor="val_accuracy",patience=5,mode="max")
Model.compile(optimizer="rmsprop",loss="categorical_crossentropy",metrics=["accuracy"])

CNN_Model = Model.fit(Train_IMG_Set,validation_data=Validation_IMG_Set, callbacks=Call_Back, epochs=50)

!nvidia-smi

